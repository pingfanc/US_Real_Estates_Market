{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4983f36-beea-4129-8941-98a8b40c3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "host=\"13.43.84.151\"\n",
    "dbname=\"postgres\"\n",
    "user=\"ping-fan.chen.23@ucl.ac.uk\"\n",
    "password=\"khsLcR\"\n",
    "port=\"5432\"\n",
    "schema=\"schema_pingfanchen23uclacuk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc2d115-f204-4d87-a9ca-c9d83d4e3eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect (\n",
    "    host=host,\n",
    "    dbname=dbname,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    port=port\n",
    ")\n",
    "print(\"Database connection established\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724503c5-c025-4e63-8a5d-4bfd83cb9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1015k  100 1015k    0     0   659k      0  0:00:01  0:00:01 --:--:--  659k\n"
     ]
    }
   ],
   "source": [
    "# fetch the java driver for postgress to allow Spark to connect to postgress\n",
    "!curl -o postgresql-42.3.2.jar https://jdbc.postgresql.org/download/postgresql-42.3.2.jar\n",
    "# uses the curl command to download the PostgreSQL JDBC driver from the official site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0308bb-3708-4453-b068-c1bb6fc54bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/dataengineer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/dataengineer/postgresql-42.3.2.jar'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd() # assigns the current working directory to the variable current_dir\n",
    "print(current_dir)\n",
    "\n",
    "jar_location = current_dir + \"/postgresql-42.3.2.jar\"\n",
    "# Constructs the file path for the PostgreSQL JDBC driver JAR file by appending the filename to the current directory path\n",
    "jar_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c333c2-87ec-4436-8b57-fd80b80388cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/03 18:34:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.driver.extraClassPath\", jar_location)\\\n",
    "    .appName(\"Enhanced Data Warehouse ETL\") \\\n",
    "    .getOrCreate()\n",
    "# Sets the configuration property spark.driver.extraClassPath to the path of the JDBC driver.\n",
    "# This tells Spark where to find the driver for the database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e027e3d-00ac-4f5d-8366-72d9815d26ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+-----+-----------------+---------------+----------+-------+--------+\n",
      "|_c0|zip_code|          city|state|           county|       timezone|area_codes|    lat|     lon|\n",
      "+---+--------+--------------+-----+-----------------+---------------+----------+-------+--------+\n",
      "|  0|   35004|         Moody|   AL| St. Clair County|America/Chicago|   ['205']|33.6034|-86.4944|\n",
      "|  1|   35005|    Adamsville|   AL| Jefferson County|America/Chicago|   ['205']|33.5929| -86.994|\n",
      "|  2|   35006|         Adger|   AL| Jefferson County|America/Chicago|   ['205']|33.4462| -87.223|\n",
      "|  3|   35007|     Alabaster|   AL|    Shelby County|America/Chicago|   ['205']|33.2187|-86.7835|\n",
      "|  4|   35010|Alexander City|   AL|Tallapoosa County|America/Chicago|   ['256']|32.9011|-85.9178|\n",
      "|  5|   35011|Alexander City|   AL|Tallapoosa County|America/Chicago|   ['256']|32.9394|-85.9466|\n",
      "|  6|   35013|       Allgood|   AL|    Blount County|America/Chicago|   ['205']|33.9119|-86.5094|\n",
      "|  7|   35014|        Alpine|   AL| Talladega County|America/Chicago|   ['256']|33.3452|-86.2657|\n",
      "|  8|   35015|         Alton|   AL| Jefferson County|America/Chicago|   ['205']|33.5795|-86.6376|\n",
      "|  9|   35016|          Arab|   AL|  Marshall County|America/Chicago|   ['256']|34.3218|-86.4969|\n",
      "| 10|   35019|     Baileyton|   AL|   Cullman County|America/Chicago|        []|34.3045|-86.6353|\n",
      "| 11|   35020|      Bessemer|   AL| Jefferson County|America/Chicago|   ['205']|33.4019|-86.9432|\n",
      "| 12|   35021|      Bessemer|   AL| Jefferson County|America/Chicago|   ['205']|33.4014|-86.9547|\n",
      "| 13|   35022|      Bessemer|   AL| Jefferson County|America/Chicago|   ['205']|33.3337|-86.9604|\n",
      "| 14|   35023|      Bessemer|   AL| Jefferson County|America/Chicago|   ['205']|33.4626|-87.0926|\n",
      "| 15|   35031|  Blountsville|   AL|    Blount County|America/Chicago|   ['205']|34.1179|-86.5621|\n",
      "| 16|   35032|       Bon Air|   AL| Talladega County|America/Chicago|        []|33.2638|-86.3359|\n",
      "| 17|   35033|        Bremen|   AL|   Cullman County|America/Chicago|   ['256']|33.9459|-87.0131|\n",
      "| 18|   35034|         Brent|   AL|      Bibb County|America/Chicago|   ['205']|32.9234|-87.2762|\n",
      "| 19|   35035|    Brierfield|   AL|      Bibb County|America/Chicago|        []|33.0694|-86.9791|\n",
      "+---+--------+--------------+-----+-----------------+---------------+----------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 18:37:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , zip_code, city, state, county, timezone, area_codes, lat, lon\n",
      " Schema: _c0, zip_code, city, state, county, timezone, area_codes, lat, lon\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/dataengineer/df_states_zip.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lag, col\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, when, lit, lead\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "df = spark.read.csv(\"df_states_zip.csv\", header=True, inferSchema=True)\n",
    "# Show the CSV file before cleaning \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e7090c-b3cc-44bc-acf9-665313fcb137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|    Label (Grouping)|Median value (dollars)|\n",
      "+--------------------+----------------------+\n",
      "|             Alabama|                  NULL|\n",
      "|            Estimate|               200,900|\n",
      "|              Alaska|                  NULL|\n",
      "|            Estimate|               336,900|\n",
      "|             Arizona|                  NULL|\n",
      "|            Estimate|               402,800|\n",
      "|            Arkansas|                  NULL|\n",
      "|            Estimate|               179,800|\n",
      "|          California|                  NULL|\n",
      "|            Estimate|               715,900|\n",
      "|            Colorado|                  NULL|\n",
      "|            Estimate|               531,100|\n",
      "|         Connecticut|                  NULL|\n",
      "|            Estimate|               347,200|\n",
      "|            Delaware|                  NULL|\n",
      "|            Estimate|               337,200|\n",
      "|District of Columbia|                  NULL|\n",
      "|            Estimate|               711,100|\n",
      "|             Florida|                  NULL|\n",
      "|            Estimate|               354,100|\n",
      "+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 09:33:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|               State|Median value (dollars)|\n",
      "+--------------------+----------------------+\n",
      "|              Alaska|               200,900|\n",
      "|             Arizona|               336,900|\n",
      "|            Arkansas|               402,800|\n",
      "|          California|               179,800|\n",
      "|            Colorado|               715,900|\n",
      "|         Connecticut|               531,100|\n",
      "|            Delaware|               347,200|\n",
      "|District of Columbia|               337,200|\n",
      "|             Florida|               711,100|\n",
      "|             Georgia|               354,100|\n",
      "|              Hawaii|               297,400|\n",
      "|               Idaho|               820,100|\n",
      "|            Illinois|               432,500|\n",
      "|             Indiana|               251,600|\n",
      "|                Iowa|               208,700|\n",
      "|              Kansas|               194,600|\n",
      "|            Kentucky|               206,600|\n",
      "|           Louisiana|               196,300|\n",
      "|               Maine|               209,200|\n",
      "|            Maryland|               290,600|\n",
      "+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "median_value_df = spark.read.csv(\"median_value.csv\", header=True, inferSchema=True)\n",
    "median_value_df.show()\n",
    "\n",
    "# Define a window spec to look ahead by one row\n",
    "windowSpec = Window.orderBy(lit(0))\n",
    "\n",
    "# Shift the 'Median value (dollars)' column up by one row\n",
    "median_value_df = median_value_df.withColumn(\"shifted_median_value\", lag(\"Median value (dollars)\").over(windowSpec))\n",
    "\n",
    "# Filter out the 'Estimate' rows and keep the rows with state names\n",
    "# Then drop the original 'Median value (dollars)' column\n",
    "# Lastly, remove rows where the 'shifted_median_value' is null\n",
    "median_value_clean = median_value_df.filter(~col(\"Label (Grouping)\").contains(\"Estimate\")) \\\n",
    "                                    .drop(\"Median value (dollars)\") \\\n",
    "                                    .filter(col(\"shifted_median_value\").isNotNull()) \\\n",
    "                                    .withColumnRenamed(\"shifted_median_value\", \"Median value (dollars)\") \\\n",
    "                                    .withColumnRenamed(\"Label (Grouping)\", \"State\")\n",
    "\n",
    "# Show the cleaned DataFrame\n",
    "median_value_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "782aecb2-f3e1-4ae7-aaac-4313f9d29041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------------+\n",
      "|    Label (Grouping)|Lower value quartile (dollars)|\n",
      "+--------------------+------------------------------+\n",
      "|             Alabama|                          NULL|\n",
      "|            Estimate|                       105,000|\n",
      "|              Alaska|                          NULL|\n",
      "|            Estimate|                       232,200|\n",
      "|             Arizona|                          NULL|\n",
      "|            Estimate|                       262,500|\n",
      "|            Arkansas|                          NULL|\n",
      "|            Estimate|                        98,300|\n",
      "|          California|                          NULL|\n",
      "|            Estimate|                       460,900|\n",
      "|            Colorado|                          NULL|\n",
      "|            Estimate|                       366,900|\n",
      "|         Connecticut|                          NULL|\n",
      "|            Estimate|                       240,600|\n",
      "|            Delaware|                          NULL|\n",
      "|            Estimate|                       228,600|\n",
      "|District of Columbia|                          NULL|\n",
      "|            Estimate|                       468,200|\n",
      "|             Florida|                          NULL|\n",
      "|            Estimate|                       222,500|\n",
      "+--------------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 09:33:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------------+\n",
      "|               State|Lower value quartile (dollars)|\n",
      "+--------------------+------------------------------+\n",
      "|              Alaska|                       105,000|\n",
      "|             Arizona|                       232,200|\n",
      "|            Arkansas|                       262,500|\n",
      "|          California|                        98,300|\n",
      "|            Colorado|                       460,900|\n",
      "|         Connecticut|                       366,900|\n",
      "|            Delaware|                       240,600|\n",
      "|District of Columbia|                       228,600|\n",
      "|             Florida|                       468,200|\n",
      "|             Georgia|                       222,500|\n",
      "|              Hawaii|                       175,300|\n",
      "|               Idaho|                       513,300|\n",
      "|            Illinois|                       293,700|\n",
      "|             Indiana|                       148,100|\n",
      "|                Iowa|                       126,400|\n",
      "|              Kansas|                       117,700|\n",
      "|            Kentucky|                       108,400|\n",
      "|           Louisiana|                       110,600|\n",
      "|               Maine|                       116,600|\n",
      "|            Maryland|                       165,800|\n",
      "+--------------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 09:33:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "lower_value_df = spark.read.csv('lower_value.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Show the initial state of the DataFrame\n",
    "lower_value_df.show()\n",
    "\n",
    "# Define a window spec to look ahead by one row\n",
    "windowSpec = Window.orderBy(lit(0))\n",
    "\n",
    "# Shift the 'Lower value (dollars)' column up by one row\n",
    "lower_value_df = lower_value_df.withColumn(\"shifted_lower_value\", lag(\"Lower value quartile (dollars)\").over(windowSpec))\n",
    "\n",
    "# Filter out the 'Estimate' rows and keep the rows which have the state names \n",
    "# Next, drop the original 'Lower value (dollars)' column\n",
    "# Lastly, remove rows where the 'shifted_lower_value' is null\n",
    "lower_value_clean = lower_value_df.filter(~col(\"Label (Grouping)\").contains(\"Estimate\")) \\\n",
    "                                  .drop(\"Lower value quartile (dollars)\") \\\n",
    "                                  .filter(col(\"shifted_lower_value\").isNotNull()) \\\n",
    "                                  .withColumnRenamed(\"shifted_lower_value\", \"Lower value quartile (dollars)\") \\\n",
    "                                  .withColumnRenamed(\"Label (Grouping)\", \"State\")\n",
    "\n",
    "# Show the cleaned DataFrame\n",
    "lower_value_clean.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8cd310-bd28-4d96-8ad6-17d3d547274e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 09:33:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 09:33:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "# JDBC URL\n",
    "url = f\"jdbc:postgresql://{host}:{port}/{dbname}?currentSchema={schema}\"\n",
    "\n",
    "# Connection properties\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Current directory and JDBC driver location\n",
    "current_dir = os.getcwd()\n",
    "jar_location = os.path.join(current_dir, \"postgresql-42.3.2.jar\")\n",
    "\n",
    "# Write the cleaned median value DataFrame to PostgreSQL\n",
    "median_value_clean.write.jdbc(url=url, table=\"median_value_table\", mode=\"overwrite\", properties=properties)\n",
    "\n",
    "# Write the cleaned upper value DataFrame to PostgreSQL\n",
    "upper_value_clean.write.jdbc(url=url, table=\"upper_value_table\", mode=\"overwrite\", properties=properties)\n",
    "\n",
    "# Write the cleaned lower value DataFrame to PostgreSQL\n",
    "lower_value_clean.write.jdbc(url=url, table=\"lower_value_table\", mode=\"overwrite\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aaef88-43f0-4548-8fd6-f335d113460a",
   "metadata": {},
   "source": [
    "We can execute a simple SQL query to **combine the tables** of upper, median, and lower quartile estimates using state names as the key. After querying, this consolidated Spark dataframe can then be stored in our Postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34b21c93-645c-4286-a355-f08e2c97eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------+-----------+\n",
      "|               State|Upper_Value|Median_Value|Lower_Value|\n",
      "+--------------------+-----------+------------+-----------+\n",
      "|              Alaska|    331,200|     200,900|    105,000|\n",
      "|             Arizona|    455,200|     336,900|    232,200|\n",
      "|            Arkansas|    602,700|     402,800|    262,500|\n",
      "|          California|    290,700|     179,800|     98,300|\n",
      "|            Colorado|  1,083,100|     715,900|    460,900|\n",
      "|         Connecticut|    737,500|     531,100|    366,900|\n",
      "|            Delaware|    504,900|     347,200|    240,600|\n",
      "|District of Columbia|    468,200|     337,200|    228,600|\n",
      "|             Florida|  1,057,600|     711,100|    468,200|\n",
      "|             Georgia|    524,200|     354,100|    222,500|\n",
      "|              Hawaii|    450,200|     297,400|    175,300|\n",
      "|               Idaho|  1,133,500|     820,100|    513,300|\n",
      "|            Illinois|    638,200|     432,500|    293,700|\n",
      "|             Indiana|    383,500|     251,600|    148,100|\n",
      "|                Iowa|    320,100|     208,700|    126,400|\n",
      "|              Kansas|    311,400|     194,600|    117,700|\n",
      "|            Kentucky|    341,200|     206,600|    108,400|\n",
      "|           Louisiana|    310,700|     196,300|    110,600|\n",
      "|               Maine|    318,300|     209,200|    116,600|\n",
      "|            Maryland|    447,700|     290,600|    165,800|\n",
      "+--------------------+-----------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:08:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Data Joining\").getOrCreate()\n",
    "\n",
    "# Given the `upper_value_clean`, `median_value_clean`, and `lower_value_clean` data frame we already defined above\n",
    "# Let's register these DataFrames as temporary views\n",
    "upper_value_clean.createOrReplaceTempView(\"upper_value_view\")\n",
    "median_value_clean.createOrReplaceTempView(\"median_value_view\")\n",
    "lower_value_clean.createOrReplaceTempView(\"lower_value_view\")\n",
    "\n",
    "# Perform the SQL join query using state as the key, combining the upper,median,lower quartile values together \n",
    "join_query = \"\"\"\n",
    "SELECT \n",
    "  u.State, \n",
    "  u.`Upper value quartile (dollars)` AS Upper_Value,\n",
    "  m.`Median value (dollars)` AS Median_Value,\n",
    "  l.`Lower value quartile (dollars)` AS Lower_Value\n",
    "FROM \n",
    "  upper_value_view u\n",
    "JOIN \n",
    "  median_value_view m \n",
    "ON \n",
    "  u.State = m.State\n",
    "JOIN \n",
    "  lower_value_view l\n",
    "ON \n",
    "  u.State = l.State\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "combined_quartile_df = spark.sql(join_query)\n",
    "\n",
    "# Show the results\n",
    "combined_quartile_df.show()\n",
    "\n",
    "# Write the cleaned quartile value DataFrame to PostgreSQL\n",
    "combined_quartile_df.write.jdbc(url=url, table=\"combined_value_quartile\", mode=\"overwrite\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70508e7c-52f3-4fbd-aa97-35e9422ec4d8",
   "metadata": {},
   "source": [
    "Next we’ll import the **fourth csv table from ACS**, detailing the estimated number of houses in each state, categorized by price ranges, ranging from less than 50,000 USD to more than 1,000,000 USD. Given that this table is larger and more complicated, we utilize pandas for cleaning and then convert the cleaned pandas dataframe into a Spark dataframe. Finally, we store the spark dataframe in the Postgres database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a701cb9-6939-4ebd-99d9-ff33fd2d25a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label (Grouping)</th>\n",
       "      <th>Total:</th>\n",
       "      <th>Total:!!Less than $50,000</th>\n",
       "      <th>Total:!!$50,000 to $99,999</th>\n",
       "      <th>Total:!!$100,000 to $149,999</th>\n",
       "      <th>Total:!!$150,000 to $199,999</th>\n",
       "      <th>Total:!!$200,000 to $299,999</th>\n",
       "      <th>Total:!!$300,000 to $499,999</th>\n",
       "      <th>Total:!!$500,000 to $999,999</th>\n",
       "      <th>Total:!!$1,000,000 or more</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estimate</td>\n",
       "      <td>1,416,333</td>\n",
       "      <td>147,494</td>\n",
       "      <td>186,145</td>\n",
       "      <td>179,651</td>\n",
       "      <td>192,181</td>\n",
       "      <td>298,254</td>\n",
       "      <td>278,735</td>\n",
       "      <td>115,476</td>\n",
       "      <td>18,397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estimate</td>\n",
       "      <td>181,586</td>\n",
       "      <td>10,015</td>\n",
       "      <td>6,103</td>\n",
       "      <td>7,964</td>\n",
       "      <td>11,081</td>\n",
       "      <td>38,637</td>\n",
       "      <td>75,646</td>\n",
       "      <td>29,463</td>\n",
       "      <td>2,677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label (Grouping)     Total: Total:!!Less than $50,000  \\\n",
       "0          Alabama        NaN                       NaN   \n",
       "1         Estimate  1,416,333                   147,494   \n",
       "2           Alaska        NaN                       NaN   \n",
       "3         Estimate    181,586                    10,015   \n",
       "4          Arizona        NaN                       NaN   \n",
       "\n",
       "  Total:!!$50,000 to $99,999 Total:!!$100,000 to $149,999  \\\n",
       "0                        NaN                          NaN   \n",
       "1                    186,145                      179,651   \n",
       "2                        NaN                          NaN   \n",
       "3                      6,103                        7,964   \n",
       "4                        NaN                          NaN   \n",
       "\n",
       "  Total:!!$150,000 to $199,999 Total:!!$200,000 to $299,999  \\\n",
       "0                          NaN                          NaN   \n",
       "1                      192,181                      298,254   \n",
       "2                          NaN                          NaN   \n",
       "3                       11,081                       38,637   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "  Total:!!$300,000 to $499,999 Total:!!$500,000 to $999,999  \\\n",
       "0                          NaN                          NaN   \n",
       "1                      278,735                      115,476   \n",
       "2                          NaN                          NaN   \n",
       "3                       75,646                       29,463   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "  Total:!!$1,000,000 or more  \n",
       "0                        NaN  \n",
       "1                     18,397  \n",
       "2                        NaN  \n",
       "3                      2,677  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Total:</th>\n",
       "      <th>Less than $50,000</th>\n",
       "      <th>$50,000 to $99,999</th>\n",
       "      <th>$100,000 to $149,999</th>\n",
       "      <th>$150,000 to $199,999</th>\n",
       "      <th>$200,000 to $299,999</th>\n",
       "      <th>$300,000 to $499,999</th>\n",
       "      <th>$500,000 to $999,999</th>\n",
       "      <th>$1,000,000 or more</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1,416,333</td>\n",
       "      <td>147,494</td>\n",
       "      <td>186,145</td>\n",
       "      <td>179,651</td>\n",
       "      <td>192,181</td>\n",
       "      <td>298,254</td>\n",
       "      <td>278,735</td>\n",
       "      <td>115,476</td>\n",
       "      <td>18,397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>181,586</td>\n",
       "      <td>10,015</td>\n",
       "      <td>6,103</td>\n",
       "      <td>7,964</td>\n",
       "      <td>11,081</td>\n",
       "      <td>38,637</td>\n",
       "      <td>75,646</td>\n",
       "      <td>29,463</td>\n",
       "      <td>2,677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>1,921,746</td>\n",
       "      <td>115,424</td>\n",
       "      <td>67,678</td>\n",
       "      <td>57,890</td>\n",
       "      <td>80,092</td>\n",
       "      <td>265,323</td>\n",
       "      <td>692,276</td>\n",
       "      <td>541,367</td>\n",
       "      <td>101,696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>808,558</td>\n",
       "      <td>82,513</td>\n",
       "      <td>123,326</td>\n",
       "      <td>109,924</td>\n",
       "      <td>129,888</td>\n",
       "      <td>175,545</td>\n",
       "      <td>129,125</td>\n",
       "      <td>47,983</td>\n",
       "      <td>10,254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>California</td>\n",
       "      <td>7,565,502</td>\n",
       "      <td>193,507</td>\n",
       "      <td>136,690</td>\n",
       "      <td>103,683</td>\n",
       "      <td>110,071</td>\n",
       "      <td>331,993</td>\n",
       "      <td>1,297,381</td>\n",
       "      <td>3,253,409</td>\n",
       "      <td>2,138,768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State     Total: Less than $50,000 $50,000 to $99,999  \\\n",
       "0     Alabama  1,416,333           147,494            186,145   \n",
       "2      Alaska    181,586            10,015              6,103   \n",
       "4     Arizona  1,921,746           115,424             67,678   \n",
       "6    Arkansas    808,558            82,513            123,326   \n",
       "8  California  7,565,502           193,507            136,690   \n",
       "\n",
       "  $100,000 to $149,999 $150,000 to $199,999 $200,000 to $299,999  \\\n",
       "0              179,651              192,181              298,254   \n",
       "2                7,964               11,081               38,637   \n",
       "4               57,890               80,092              265,323   \n",
       "6              109,924              129,888              175,545   \n",
       "8              103,683              110,071              331,993   \n",
       "\n",
       "  $300,000 to $499,999 $500,000 to $999,999 $1,000,000 or more  \n",
       "0              278,735              115,476             18,397  \n",
       "2               75,646               29,463              2,677  \n",
       "4              692,276              541,367            101,696  \n",
       "6              129,125               47,983             10,254  \n",
       "8            1,297,381            3,253,409          2,138,768  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|               State|   Total:|Less than $50,000|$50,000 to $99,999|$100,000 to $149,999|$150,000 to $199,999|$200,000 to $299,999|$300,000 to $499,999|$500,000 to $999,999|$1,000,000 or more|\n",
      "+--------------------+---------+-----------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|             Alabama|1,416,333|          147,494|           186,145|             179,651|             192,181|             298,254|             278,735|             115,476|            18,397|\n",
      "|              Alaska|  181,586|           10,015|             6,103|               7,964|              11,081|              38,637|              75,646|              29,463|             2,677|\n",
      "|             Arizona|1,921,746|          115,424|            67,678|              57,890|              80,092|             265,323|             692,276|             541,367|           101,696|\n",
      "|            Arkansas|  808,558|           82,513|           123,326|             109,924|             129,888|             175,545|             129,125|              47,983|            10,254|\n",
      "|          California|7,565,502|          193,507|           136,690|             103,683|             110,071|             331,993|           1,297,381|           3,253,409|         2,138,768|\n",
      "|            Colorado|1,584,309|           49,320|            33,337|              22,705|              36,085|             115,397|             475,693|             684,651|           167,121|\n",
      "|         Connecticut|  949,839|           24,707|            15,660|              35,444|              74,994|             226,313|             332,554|             182,537|            57,630|\n",
      "|            Delaware|  298,075|           15,560|             8,229|               9,604|              21,306|              68,996|             114,654|              51,791|             7,935|\n",
      "|District of Columbia|  134,120|            1,403|               534|               1,027|               1,766|               6,625|              26,336|              59,670|            36,759|\n",
      "|             Florida|5,929,801|          303,782|           272,636|             272,661|             407,732|           1,054,549|           2,047,710|           1,226,674|           344,057|\n",
      "|             Georgia|2,695,885|          163,181|           183,535|             180,555|             264,069|             572,086|             815,357|             441,440|            75,662|\n",
      "|              Hawaii|  309,687|            6,078|             4,963|               4,092|               3,134|              10,998|              44,885|             129,992|           105,545|\n",
      "|               Idaho|  518,837|           23,676|            13,280|              13,866|              21,227|              61,904|             189,351|             163,955|            31,578|\n",
      "|            Illinois|3,392,312|          188,060|           309,443|             363,553|             424,317|             785,800|             870,501|             374,017|            76,621|\n",
      "|             Indiana|1,929,865|          120,076|           217,661|             257,866|             322,482|             476,142|             389,736|             125,682|            20,220|\n",
      "|                Iowa|  958,700|           65,582|           119,801|             144,438|             163,916|             210,800|             185,507|              58,641|            10,015|\n",
      "|              Kansas|  795,989|           73,404|           107,423|              97,100|             107,807|             166,002|             168,163|              65,828|            10,262|\n",
      "|            Kentucky|1,257,737|          123,171|           152,843|             165,175|             200,349|             284,893|             237,496|              80,311|            13,499|\n",
      "|           Louisiana|1,229,012|          124,906|           134,722|             133,413|             190,535|             308,780|             239,403|              80,373|            16,880|\n",
      "|               Maine|  448,772|           25,734|            30,640|              39,220|              44,704|              92,734|             130,270|              73,785|            11,685|\n",
      "+--------------------+---------+-----------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_file_path = 'num_of_houses_by_price_range.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df.head()\n",
    "\n",
    "# Now we can do some data cleaning: \n",
    "# Rename the first column name to \"State\"\n",
    "df.rename(columns={df.columns[0]: 'State'}, inplace=True)\n",
    "\n",
    "# Remove the \"Total:!!\" prefix from the column names starting from the third column\n",
    "df.columns = [col if idx < 2 else col.replace('Total:!!', '') for idx, col in enumerate(df.columns)]\n",
    "\n",
    "# Shift all the data points one step upward in columns other than 'State'\n",
    "for column in df.columns[1:]: #  iterate over each column, except 'State', and shift them\n",
    "    df[column] = df[column].shift(-1)\n",
    "\n",
    "# Drop all rows which contains NaN value \n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "df_cleaned.head()\n",
    "\n",
    "# Convert the pandas DataFrame to the Spark DataFrame\n",
    "spark_df_num_of_houses = spark.createDataFrame(df_cleaned)\n",
    "spark_df_num_of_houses.show()\n",
    "\n",
    "# Write the Spark DataFrame to the PostgreSQL database\n",
    "spark_df_num_of_houses.write.jdbc(url=url, table=\"num_of_houses_by_price_range\", mode='overwrite', properties=properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b239c2-a6ac-497e-8fc2-28f2a75e4c0a",
   "metadata": {},
   "source": [
    "Finally let's print out **all existing tables** in our Postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecfd5678-3cb7-41f8-8ff7-38b8c2e23340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from table: people\n",
      "   id      name      city profession\n",
      "0   1  John Doe  New York   Engineer\n",
      "1   2  John Doe  New York   Engineer\n",
      "2  34  John Doe  New York   Engineer\n",
      "3  35  John Doe  New York   Engineer\n",
      "4  36  John Doe  New York   Engineer\n",
      "Data from table: num_of_houses_by_price_range\n",
      "        State     Total: Less than $50,000 $50,000 to $99,999  \\\n",
      "0     Alabama  1,416,333           147,494            186,145   \n",
      "1      Alaska    181,586            10,015              6,103   \n",
      "2     Arizona  1,921,746           115,424             67,678   \n",
      "3    Arkansas    808,558            82,513            123,326   \n",
      "4  California  7,565,502           193,507            136,690   \n",
      "\n",
      "  $100,000 to $149,999 $150,000 to $199,999 $200,000 to $299,999  \\\n",
      "0              179,651              192,181              298,254   \n",
      "1                7,964               11,081               38,637   \n",
      "2               57,890               80,092              265,323   \n",
      "3              109,924              129,888              175,545   \n",
      "4              103,683              110,071              331,993   \n",
      "\n",
      "  $300,000 to $499,999 $500,000 to $999,999 $1,000,000 or more  \n",
      "0              278,735              115,476             18,397  \n",
      "1               75,646               29,463              2,677  \n",
      "2              692,276              541,367            101,696  \n",
      "3              129,125               47,983             10,254  \n",
      "4            1,297,381            3,253,409          2,138,768  \n",
      "Data from table: combined_value_quartile\n",
      "        State Upper_Value Median_Value Lower_Value\n",
      "0      Alaska     331,200      200,900     105,000\n",
      "1     Arizona     455,200      336,900     232,200\n",
      "2    Arkansas     602,700      402,800     262,500\n",
      "3  California     290,700      179,800      98,300\n",
      "4    Colorado   1,083,100      715,900     460,900\n",
      "Data from table: median_value_table\n",
      "        State Median value (dollars)\n",
      "0      Alaska                200,900\n",
      "1     Arizona                336,900\n",
      "2    Arkansas                402,800\n",
      "3  California                179,800\n",
      "4    Colorado                715,900\n",
      "Data from table: upper_value_table\n",
      "        State Upper value quartile (dollars)\n",
      "0      Alaska                        331,200\n",
      "1     Arizona                        455,200\n",
      "2    Arkansas                        602,700\n",
      "3  California                        290,700\n",
      "4    Colorado                      1,083,100\n",
      "Data from table: lower_value_table\n",
      "        State Lower value quartile (dollars)\n",
      "0      Alaska                        105,000\n",
      "1     Arizona                        232,200\n",
      "2    Arkansas                        262,500\n",
      "3  California                         98,300\n",
      "4    Colorado                        460,900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95/1827585956.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "/tmp/ipykernel_95/1827585956.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "/tmp/ipykernel_95/1827585956.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "/tmp/ipykernel_95/1827585956.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "/tmp/ipykernel_95/1827585956.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n",
      "/tmp/ipykernel_95/1827585956.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password, port=port)\n",
    "# Create Cursor object \n",
    "cur = conn.cursor()\n",
    "\n",
    "# Query to fetch table names in the specified schema\n",
    "cur.execute(f\"\"\"\n",
    "SELECT table_name FROM information_schema.tables\n",
    "WHERE table_schema = '{schema}' AND table_type = 'BASE TABLE';\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all table names\n",
    "tables = cur.fetchall()\n",
    "\n",
    "# Iterate over table names and select data from each table\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    print(f\"Data from table: {table_name}\")\n",
    "    \n",
    "    # Fetch data from each table\n",
    "    query = f\"SELECT * FROM {schema}.{table_name};\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df.head())  # Adjust as per your need\n",
    "    \n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f058fec1-cb9a-4be8-8be8-8144d541492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckdb in /usr/local/lib/python3.11/site-packages (0.10.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# To use the latest version of duckdb\n",
    "!pip install duckdb\n",
    "\n",
    "# Assuming you have DuckDB installed and the duckdb Python package\n",
    "import duckdb\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db2b31a8-d33c-48aa-8fe5-d9e35b385f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/03 10:16:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "ename": "IOException",
     "evalue": "IO Error: No files found that match the pattern \"/home/jovyan/DE w6 workshops/combined_value_quartile.parquet/part-00000-eb3d1bcb-b705-4c99-8f52-25785be2e534-c000.snappy.parquet\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m combined_quartile_df\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mparquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined_value_quartile.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the Parquet file into DuckDB as a table\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE TABLE combined_value_quartile AS SELECT * FROM read_parquet(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/jovyan/DE w6 workshops/combined_value_quartile.parquet/part-00000-eb3d1bcb-b705-4c99-8f52-25785be2e534-c000.snappy.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Perform a query in DuckDB to verify the data is loaded\u001b[39;00m\n\u001b[1;32m      8\u001b[0m result \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM combined_value_quartile LIMIT 10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mIOException\u001b[0m: IO Error: No files found that match the pattern \"/home/jovyan/DE w6 workshops/combined_value_quartile.parquet/part-00000-eb3d1bcb-b705-4c99-8f52-25785be2e534-c000.snappy.parquet\""
     ]
    }
   ],
   "source": [
    "# Save the combined DataFrame as a Parquet file\n",
    "combined_quartile_df.write.parquet(\"combined_value_quartile.parquet\", mode=\"overwrite\")\n",
    "\n",
    "# Load the Parquet file into DuckDB as a table\n",
    "con.execute(\"CREATE TABLE combined_value_quartile AS SELECT * FROM read_parquet('/home/jovyan/DE w6 workshops/combined_value_quartile.parquet/part-00000-eb3d1bcb-b705-4c99-8f52-25785be2e534-c000.snappy.parquet')\")\n",
    "\n",
    "# Perform a query in DuckDB to verify the data is loaded\n",
    "result = con.execute(\"SELECT * FROM combined_value_quartile LIMIT 10\").fetchall()\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "297fd03c-3c6d-46c4-9243-9ede0a52c289",
   "metadata": {},
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: No files found that match the pattern \"num_of_houses.parquet\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m spark_df_num_of_houses\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mparquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_of_houses.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the Parquet file into DuckDB as a table\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE TABLE num_of_houses AS SELECT * FROM read_parquet(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_of_houses.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Perform a query in DuckDB to verify the data is loaded\u001b[39;00m\n\u001b[1;32m      8\u001b[0m result \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM num_of_houses LIMIT 10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mIOException\u001b[0m: IO Error: No files found that match the pattern \"num_of_houses.parquet\""
     ]
    }
   ],
   "source": [
    "# Save the spark_df_num_of_houses DataFrame as a Parquet file\n",
    "spark_df_num_of_houses.write.parquet(\"num_of_houses.parquet\", mode=\"overwrite\")\n",
    "\n",
    "# Load the Parquet file into DuckDB as a table\n",
    "con.execute(\"CREATE TABLE num_of_houses AS SELECT * FROM read_parquet('num_of_houses.parquet')\")\n",
    "\n",
    "# Perform a query in DuckDB to verify the data is loaded\n",
    "result = con.execute(\"SELECT * FROM num_of_houses LIMIT 10\").fetchall()\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bc370-9be7-4435-a490-d9e921eca04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ai8-sym": {
   "notebook_id": "d74e9caa-8403-4458-8659-ddbdddf43dbb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
